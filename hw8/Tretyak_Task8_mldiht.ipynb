{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt\">Домашнее задание №8 </span>\n",
    "\n",
    "<span style=\"color: red; font-size: 14pt\">Deadline: 20.05.2017 23:59:59</span>\n",
    "\n",
    "<span style=\"font-size: 10pt\">ФИВТ, АПТ, Курс по машинному обучению, Весна 2017, Модуль Unspervised Learning, </span>\n",
    "\n",
    "<span style=\"color:blue; font-size: 10pt\">Alexey Romanenko, </span>\n",
    "<span style=\"color:blue; font-size: 10pt; font-family: 'Verdana'\">alexromsput@gmail.com</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Organization Info</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дополнительный материал для выполнения дз**:\n",
    "- Воронцов К. В. Математические методы обучения по прецедентам. 2012. http://www.machinelearning.ru/wiki/images/6/6d/Voron-ML-1.pdf (разделы 5.2 и 7.1)\n",
    "- Hastie T., Tibshirani R., Friedman J. The Elements of Statistical Learning. Springer: Data Mining, Inference, and Prediction.  — 2nd ed. — Springer-Verlag. 2009. — 746 p.http://statweb.stanford.edu/~tibs/ElemStatLearn/printings/ESLII_print10.pdf (глава 14)\n",
    "\n",
    "\n",
    "\n",
    "**Оформление дз**: \n",
    "- Присылайте выполненное задание на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2017_fall <номер_группы> <фамилия>``, к примеру -- ``ML2017_fall 496 ivanov``\n",
    "- Выполненное дз сохраните в файл ``<фамилия>_<группа>_task<номер задания>.ipnb``, к примеру -- ``ML2017_496_task1.ipnb``\n",
    "\n",
    "**Вопросы**:\n",
    "- Присылайте вопросы на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2016_fall Question <Содержание вопроса>``\n",
    "\n",
    "--------\n",
    "- **PS1**: Используются автоматические фильтры, и просто не найдем ваше дз, если вы не аккуратно его подпишите.\n",
    "- **PS2**: Дедлайн жесткий, в том числе помтоу что это ДЗ последнее в курсе. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Контрольные вопросы (0 % - для самоконтроля) </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответе на вопросы своими словами (загугленный материал надо пересказать), ответ обоснуйте (напишите и ОБЪЯСНИТЕ формулки если потребуется), если не выходит, то вернитесь к лекции дополнительным материалам:\n",
    "\n",
    "**Вопрос 1**: В чём заключается проблема мультиколлинеарности?\n",
    "\n",
    "**Вопрос 2**: Какие проблемы при обучении алгоритмов возникают из-за большой разамерности пространства признаков?\n",
    "\n",
    "**Вопрос 3**: В чем суть проклятия размерности?\n",
    "\n",
    "** Вопрос 4**: Какая связь между решением задачи PCA и SVD-разложение матрицы регрессии?\n",
    "\n",
    "** Вопрос 5**: Почему в tSNE расстояние между парамми объектов измеряется \"по-стьюденту\" и как это помогает решить проблему \"скрученности\" (crowding problem)?\n",
    "\n",
    "**Вопрос 6**: На какой идее базируются алгоритмы аггломеративной кластеризации? Напишите формулу Ланса-Вильма\n",
    "\n",
    "**Вопрос 7**: Какие два шага выделяют в алгоритме кластеризации k-means?\n",
    "\n",
    "**Вопрос 8**: В чём отличия (основные упрощения) k-means от EM-алгоритма кластеризации?\n",
    "\n",
    "** Вопрос 9 **Какой принцип работы графовых алгоритмов кластеризации?\n",
    "\n",
    "** Вопрос 10 **  В чем некорректность постановки задачи кластеризации?\n",
    "\n",
    "-----------\n",
    "PS: Если проверяющий не понял ответ на большинство вопросов, то будет пичалька. Пишите так, чтобы можно было разобраться. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1 align=\"center\">Вопросы по теории (30%) </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задача 1 ** \n",
    "Ответьте на вопросы:\n",
    "\n",
    " 1) Как можно не прибегая к визуализации понять, что кластерная структура у данного облака точек отсутствует?\n",
    " 2) Какие из алгоритмов кластеризации могут выделять кластеры с ленточной структурой? \n",
    " 3) Какие алгоритмы кластеризации чувствительны к шуму и перемычкам?\n",
    " 4) Каким образом приближают «центр кластера» в нелинейных пространствах?\n",
    " 5) Каким образом можно определять число кластеров?\n",
    " \n",
    "** Задача 2 **\n",
    "Даны пять точек на числовой оси $X = (1; 5; 7; 8; 8)$, число кластеров равно 2. Рассчитайте ответ алгоритма  K-means (финальные центры кластеров), если начальные центры кластеров c1 = 1, c2 = 10.\n",
    "\n",
    "На первом шаге в первый кластер идут (1, 5), во второй - (7, 8, 8). Их центры - $(3, \\frac{23}{3})$, соответственно. Следующий шаг ничего не поменяет.\n",
    "\n",
    "** Задача 3 **\n",
    "Докажите, что the k-means всегда сходится.\n",
    "\n",
    "** Задача 4 **\n",
    "Для сжатия размерности пространства алгоритм PCA применяется датасету с количеством признаков $D = 100$. Наблюдается следующий спектр собственных значений матрицы объектов-признаков. \n",
    "<img src=\"PCA_lambda.png\" width=\"600\">\n",
    "Ответье на вопросы\n",
    "\n",
    "* 1) Высокая ли эффективная размерность пространства признаков (intrinsic dimensionality) (насколько она близка к 100)?\n",
    "* 2) Можно ли перевести датасет с помощью PCA в пространство меньшей размерности с минимальными потерями точности? Если да, то чему примерно будет равна размернось \n",
    "\n",
    "\n",
    "Близка к 100. В пространство меньшей размерности с мин потерями перейти не получится, т.к. у кривой $\\lambda(k)$ нет резких перепадов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Практическое задание 1 (30%) </h2>\n",
    "Реализуйте PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bisect import bisect_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция котороя ищет самый левый элементо который больше или равен заданного в отсортированном списке. Нужна, чтобы найти количество компонент для PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "'''\n",
    "Performs the Principal Coponent analysis of the Matrix F\n",
    "Matrix must be n * l dimensions\n",
    "where n is # features\n",
    "l is # samples\n",
    "'''\n",
    "\n",
    "def PCA(F, varRetained = 0.95, show = False):\n",
    "    # Input\n",
    "    #     F - initaial matrix \n",
    "    # Compute Covariance Matrix Sigma\n",
    "    # Input\n",
    "    (n, l) = F.shape\n",
    "    \n",
    "    Sigma = (1.0 / l * F).dot(np.transpose(F))\n",
    "    # Compute eigenvectors and eigenvalues of Sigma by SVD\n",
    "    # U, V - matrix, d - array: Sigma = U * np.diag(d) * V\n",
    "    U, d, V = np.linalg.svd(Sigma, full_matrices=True)\n",
    "    # compute the value m: number of minumum features that retains the given variance varRetaine\n",
    "    dTot = np.sum(d)\n",
    "    sort_index = d.argsort()[::-1]\n",
    "    d_sort = d[sort_index]\n",
    "    var_i = np.array([np.sum(d_sort[: i + 1]) / \\\n",
    "                dTot * 100.0 for i in range(n)]) \n",
    "    \n",
    "    i = varRetained * 100  \n",
    "    \n",
    "    for j in range(len(var_i)):\n",
    "        if var_i[j] > i:\n",
    "            break\n",
    "    print(j)#вычислите необходимое число главных компонент\n",
    "    print ('%.2f %% variance retained in % dimensions' %(var_i[j], j)) #верните число m и точность, которая достигается при этом числе главных компонент\n",
    "    \n",
    "    # plot the variance plot\n",
    "    if show:\n",
    "        plt.plot(var_i)\n",
    "        plt.xlabel('Number of Features')\n",
    "        plt.ylabel(' Percentage Variance retained')\n",
    "        plt.title('PCA $\\% \\sigma^2 $ vs # features')\n",
    "        plt.show()\n",
    "    # compute the reduced dimensional features by projection\n",
    "    U_reduced = (U.T[sort_index[:j]]).T#только m главных компонент\n",
    "    G = F.T.dot(U_reduced)#U.dot(F)#вычислить матрицу в преобразованном пространстве\n",
    "\n",
    "    return G, U_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Примените алгоритм к данным MNIST\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "X, y = load_digits(return_X_y=True)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing PCA - Principal COmponent Analysis\n",
      "15\n",
      "95.25 % variance retained in  15imensions\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEaCAYAAAAL7cBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb80f198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################################################################\n",
    "# PCA of training set\n",
    "print ('Performing PCA - Principal COmponent Analysis')\n",
    "\n",
    "Z, U_reduced = PCA(X.T, varRetained = 0.95, show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><h2 align=\"center\">Практическое задание 2 (40%) </h2> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"left\">Изучение алгоритмов кластеризации на разных выборках</h2>\n",
    "\n",
    "### Кластеризация цифр с помощью dbscan\n",
    "На данных из sklearn.datasets.load_digits примените алгоритмы кластеризации (знания о метках классов при кластеризации использовать нельзя):\n",
    " - <a href='http://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN'>dbscan </a> \n",
    " запускайте при различных параметрах eps и minsamples, для всех экспериментов можете выбрать одну метрику (вспомните семинар про  метрические алгоритмы);\n",
    " - Используя метки классов цифр, оцените качество различных кластеризаций при помощи Adjusted Mutual Information и Adjusted Rand Index. \n",
    " - визуалируйте изображения тех цифр, которые соответствуют core_points;\n",
    " - визуалируйте изображения тех цифр, которые соответствуют выбросам;\n",
    " - сделайте выводы и применимости алгоритмов.\n",
    "\n",
    "### Уменьшение палитры изображения\n",
    " - для <a href=\"https://thumbs.dreamstime.com/x/two-lorikeet-birds-2293918.jpg\"> картинки </a> \n",
    "нужно уменьшить число цветов в палитре; для этого нужно выделить кластеры в пространстве RGB, объекты соответствуют пикселам изображения; после выделения кластеров,\n",
    "все пикселы, отнесенные в один кластер, заполняются одним цветом; этот цвет может быть центроидом соответствующего кластера, медианным цветом по кластеру. \n",
    " - Попробуйте различные алгоритмы кластеризации:\n",
    "        -- KMeans\n",
    "        -- MeanShift\n",
    "        -- AgglomerativeClustering\n",
    "   Рассмотрите число кластеров K = 2, 3, 10, 20\n",
    " - Для различных кластеризаций оцените и сравните потери от уменьшения цветов при помощи\n",
    "метрики <a href=\"http://scikit-image.org/docs/dev/api/skimage.measure.html\"> SSIM</a>. Какой способ оказался лучшим?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=100, min_samples=10).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "X, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4,\n",
    "                            random_state=0)\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\"\n",
    "      % metrics.adjusted_rand_score(labels_true, labels))\n",
    "print(\"Adjusted Mutual Information: %0.3f\"\n",
    "      % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Black removed and is used for noise instead.\n",
    "unique_labels = set(labels)\n",
    "colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = 'k'\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = X[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=14)\n",
    "\n",
    "    xy = X[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
